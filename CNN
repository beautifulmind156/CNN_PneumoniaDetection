# -*- coding: utf-8 -*-
"""PneumoniaDetectionCV_withCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1iHKuxttxaZmXYRvgLpK5wupqhWezFjeQ

# Capstone - Pneumonia Detection Challenge - Modeling using CNN

### Here are the insights from CNN model experiment:

- CNN model is tried for this problem statement to get insights into challenges and compare results with using traditional CNN models for complex real world problems
- Here CNN is applied on data using: (a) traditional pixel array approach (b) data generated using Image Generators (preprocessing required for converting DICOM to PNG files)
- Experiment is done both on Grayscale and RBG data. Better results are observed with Grayscale data
- Image generators speed up the data pre-processing and useful in augmentation
- Freezing the layers is a good approach to reduce processing time
- DenseNet (with RGB data only) gives good results
- CNN Results when compared with Object Detection model YOLO, indicate object detection models are more apt for solving the problem at hand for more accurate and visible results
- Object detection models provide more justification to the results by displaying bounding boxes. CNN results are more of a black box and hence less convincing (specifically in medical fields)

Import Necessary Packages
"""

!pip install pydicom

# Commented out IPython magic to ensure Python compatibility.
import os
import pandas as pd 
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from tqdm import tqdm_notebook
from matplotlib.patches import Rectangle
import seaborn as sns
import pydicom as dcm
# %matplotlib inline
import cv2

import keras
import tensorflow as tf
import tensorflow.keras
from keras.models import Sequential, Model
from keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , BatchNormalization, MaxPooling2D, GlobalAveragePooling2D, ZeroPadding2D
from tensorflow.keras.applications import DenseNet201
from keras.preprocessing.image import ImageDataGenerator
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report,confusion_matrix
from keras.callbacks import ReduceLROnPlateau

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
os.chdir('/content/drive/MyDrive/RSNA_PneumoniaDetectionChallenge')
# %pwd

train_df = pd.read_csv('train_labels.csv')
test_df = pd.read_csv('test_labels.csv')

print(train_df.shape)
train_df.head()

"""# Modeling with CNN - using Pixel Arrays"""

# Commented out IPython magic to ensure Python compatibility.
os.chdir('/content/drive/My Drive/RSNA_PneumoniaDetectionChallenge')
# %pwd%

"""Results using RGB Pixel arrays"""

from pydicom.pixel_data_handlers.util import apply_color_lut
import cv2

resize_img_rgb = []
temp0 = train_df.iloc[:, 5]

for i in range(len(temp0)):
  temp1 = dcm.dcmread(temp0[i]).pixel_array
  rgb1 = apply_color_lut(temp1, palette='PET')
  rgb2 = cv2.resize(rgb1, (150, 150))
  resize_img_rgb.append(rgb2)
  #print(i, end = ' ')

len(resize_img_rgb)

resize_img_rgb[0].shape

x_all_rgb = np.array(resize_img_rgb)

#x_all_rgb.tofile('x_all_rgb.csv', sep=',')

print(x_all_rgb.shape)

y_train = pd.get_dummies(train_df[:13571]['Target'])

print(y_train.shape)
y_train.head()

model = Sequential()
model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,3)))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(Dropout(0.1))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Flatten())
model.add(Dense(units = 128 , activation = 'relu'))
model.add(Dropout(0.2))
model.add(Dense(units = 2 , activation = 'sigmoid'))
model.compile(optimizer = "rmsprop" , loss = 'binary_crossentropy' , metrics = ['accuracy'])
model.summary()

x_all_rgb = x_all_rgb.astype(float)

history = model.fit(x_all_rgb, y_train, batch_size = 500 ,epochs = 12)
#history = model.fit(train_generator, batch_size = 500 ,epochs = 12)

densenet = tf.keras.applications.DenseNet201(weights = 'imagenet', include_top=False, pooling = 'avg', input_shape=[150, 150, 3])
densenet.trainable = True # Using pretrained weights due to compute limitation on the worspace.

modelD = tf.keras.Sequential([
            densenet,
            tf.keras.layers.Dense(2, activation='sigmoid')
            ])

modelD.compile(
            optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False),
            loss = tf.keras.losses.BinaryCrossentropy(),
            metrics = 'accuracy'
            )

history = modelD.fit(x_all_rgb, y_train, batch_size = 64 ,epochs = 12)
#history = modelD.fit(train_generator, batch_size = 32 ,epochs = 12)

"""Results using Grayscale images"""

import cv2
resize_img = []
temp4 = train_df.iloc[:,5]

for i in range(train_df.shape[0]):
  temp = dcm.dcmread(temp4[i]).pixel_array
  #origsize_img.append(dcm.read_file(train_df.iloc[i,5]).pixel_array)
  resize_img.append(cv2.resize(temp, (150, 150)))
  #print(i, end = ' ')

len(resize_img)

resize_img[0].shape

x_all = np.array(resize_img)

#x_all.tofile('x_all.csv')

x_all = x_all.reshape(13102, 150, 150, 1)
print(x_all.shape)

y_train = pd.get_dummies(train_df[:13102]['Target'])

print(y_train.shape)
y_train.head()

model = Sequential()
model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(Dropout(0.1))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Flatten())
model.add(Dense(units = 128 , activation = 'relu'))
model.add(Dropout(0.2))
model.add(Dense(units = 2 , activation = 'sigmoid'))
model.compile(optimizer = "rmsprop" , loss = 'binary_crossentropy' , metrics = ['accuracy'])
model.summary()

#x_all = x_all.astype(float)

history = model.fit(x_all, y_train, batch_size = 500 ,epochs = 12)
#history = model.fit(train_generator, batch_size = 500 ,epochs = 12)

"""# Modeling with CNN - Using Image Generators"""

train_df.Target = train_df.Target.astype(str)

# Commented out IPython magic to ensure Python compatibility.
os.chdir('/content/drive/MyDrive/RSNA_PneumoniaDetectionChallenge/')
# %pwd%

train_df.path[0]

"""Converting DICOM to PNG files"""

# Commented out IPython magic to ensure Python compatibility.
t1 = 0
for f in train_df[0:3]['path']:   # remove "[:10]" to convert all images 
    ds = dcm.read_file(f) # read dicom image
    img = ds.pixel_array # get image array
    name = f.replace('stage2_train_images/', "").replace('.dcm','.png')
    #print(name)
    os.chdir('/content/drive/MyDrive/RSNA_PneumoniaDetectionChallenge/PNG_Train')
    cv2.imwrite(gray_image,img) # write png image
    os.chdir('/content/drive/MyDrive/RSNA_PneumoniaDetectionChallenge')  
    print(t1, end='-')
    t1=t1+1

# %pwd%

test_df.loc[0,:]

test_df[0:3]['path']

# Commented out IPython magic to ensure Python compatibility.
os.chdir('/content/drive/MyDrive/RSNA_PneumoniaDetectionChallenge')  
# %pwd

# Commented out IPython magic to ensure Python compatibility.
t1 = 0
for f in test_df[:]['path']:   # remove "[:10]" to convert all images 
    #print(f.replace('stage2_test_images/', 'stage_1_test_images/'))
    ds = dcm.read_file(f.replace('stage2_test_images/', 'stage_1_test_images/')) # read dicom image
    
    img = ds.pixel_array # get image array
    #print(img)
    name = f.replace('stage2_test_images/', "").replace('.dcm','.png')
    #print(name)
    os.chdir('/content/drive/MyDrive/RSNA_PneumoniaDetectionChallenge/PNG_Test')
    cv2.imwrite(name, img) # write png image
    os.chdir('/content/drive/MyDrive/RSNA_PneumoniaDetectionChallenge')  
    #print(t1, end='-')
    t1=t1+1

# %pwd

os.chdir('/content/drive/MyDrive/RSNA_PneumoniaDetectionChallenge/PNG_Train')
print(len(os.listdir()))
os.chdir('/content/drive/MyDrive/RSNA_PneumoniaDetectionChallenge/stage_1_train_images') 
print(len(os.listdir()))
os.chdir('/content/drive/MyDrive/RSNA_PneumoniaDetectionChallenge/')

import tensorflow as tf
train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(
    rescale=1./255,
    featurewise_center=False,
    featurewise_std_normalization=False,
    )

os.chdir('/content/drive/MyDrive/RSNA_PneumoniaDetectionChallenge/')

train_df['png_path'] = 'PNG_Train/' + train_df['path'].str.replace('stage2_train_images/', '').str.replace('.dcm','.png')
train_df.loc[0,'png_path']

train_generator = train_datagen.flow_from_dataframe(
    train_df, directory=None, 
    x_col="png_path", y_col="Target", weight_col=None,
    target_size=(150, 150), 
    color_mode = 'grayscale',
    batch_size=224, 
    validate_filenames=True
)

train_generator.n

train_generator_rgb = train_datagen.flow_from_dataframe(
    train_df, directory=None, 
    x_col="png_path", y_col="Target", weight_col=None,
    target_size=(150, 150), 
    #color_mode = 'grayscale',
    batch_size=64, 
    validate_filenames=True
)

train_generator_rgb.n

model = Sequential()
model.add(Conv2D(32 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu' , input_shape = (150,150,1)))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(Dropout(0.1))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Conv2D(64 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Conv2D(128 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Conv2D(256 , (3,3) , strides = 1 , padding = 'same' , activation = 'relu'))
model.add(Dropout(0.2))
model.add(BatchNormalization())
model.add(MaxPool2D((2,2) , strides = 2 , padding = 'same'))
model.add(Flatten())
model.add(Dense(units = 128 , activation = 'relu'))
model.add(Dropout(0.2))
model.add(Dense(units = 2 , activation = 'sigmoid'))
#model.compile(optimizer = "rmsprop" , loss = 'binary_crossentropy' , metrics = ['accuracy'])
model.compile(optimizer = "rmsprop" , loss = 'binary_crossentropy' , metrics = ['accuracy', keras.metrics.Recall()] )

model.summary()

"""*Results using Grayscale data - CNN*"""

history = model.fit(train_generator, batch_size = 224 ,epochs = 12)

densenet = tf.keras.applications.DenseNet201(weights = 'imagenet', include_top=False, pooling = 'avg', input_shape=[150, 150, 3])
densenet.trainable = True # Using pretrained weights due to compute limitation on the worspace.

modelD = tf.keras.Sequential([
            densenet,
            tf.keras.layers.Dense(2, activation='sigmoid')
            ])

modelD.compile(
            optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False),
            loss = tf.keras.losses.BinaryCrossentropy(),
            metrics = 'accuracy'
            )

"""*Results using RGB data on DenseNet*"""

#history = modelD.fit(x_all_rgb, y_train, batch_size = 32 ,epochs = 12)
history = modelD.fit(train_generator_rgb, batch_size = 32 ,epochs = 12)
